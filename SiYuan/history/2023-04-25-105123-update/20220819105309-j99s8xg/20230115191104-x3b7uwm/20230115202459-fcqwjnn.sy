{
	"ID": "20230115202459-fcqwjnn",
	"Type": "NodeDocument",
	"Properties": {
		"id": "20230115202459-fcqwjnn",
		"scroll": "{\u0026amp;quot;startId\u0026amp;quot;:\u0026amp;quot;20230115205058-mv3guix\u0026amp;quot;,\u0026amp;quot;endId\u0026amp;quot;:\u0026amp;quot;20230115210924-ef2s7h6\u0026amp;quot;,\u0026amp;quot;scrollTop\u0026amp;quot;:6223,\u0026amp;quot;focusId\u0026amp;quot;:\u0026amp;quot;20230115210924-ef2s7h6\u0026amp;quot;,\u0026amp;quot;focusStart\u0026amp;quot;:0,\u0026amp;quot;focusEnd\u0026amp;quot;:0}",
		"title": "深入浅出HashMap的设计与优化",
		"updated": "20230115210924"
	},
	"Children": [
		{
			"ID": "20230115205058-mv3guix",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20230115205058-mv3guix",
				"updated": "20230115205140"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "ArrayList 是基于数组的数据结构实现的，LinkedList 是基于链表的数据结构实现的，而我今天要讲的 HashMap 是基于哈希表的数据结构实现的。我们不妨一起来温习下常用的数据结构，这样也有助于你更好地理解后面地内容。"
				}
			]
		},
		{
			"ID": "20230115205141-6fkr9zg",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20230115205141-6fkr9zg",
				"updated": "20230115205144"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "数组：采用一段连续的存储单元来存储数据。对于指定下标的查找，时间复杂度为 O(1)，但在数组中间以及头部插入数据时，需要复制移动后面的元素。"
				}
			]
		},
		{
			"ID": "20230115205145-fx6gpox",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20230115205145-fx6gpox",
				"updated": "20230115205149"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "链表：一种在物理存储单元上非连续、非顺序的存储结构，数据元素的逻辑顺序是通过链表中的指针链接次序实现的。"
				}
			]
		},
		{
			"ID": "20230115205149-k0lcsoa",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20230115205149-k0lcsoa",
				"updated": "20230115205202"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "链表由一系列结点（链表中每一个元素）组成，结点可以在运行时动态生成。每个结点都包含“存储数据单元的数据域”和“存储下一个结点地址的指针域”这两个部分。"
				}
			]
		},
		{
			"ID": "20230115205203-f7bzsna",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20230115205203-f7bzsna",
				"updated": "20230115205208"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "由于链表不用必须按顺序存储，所以链表在插入的时候可以达到 O(1) 的复杂度，但查找一个结点或者访问特定编号的结点需要 O(n) 的时间。"
				}
			]
		},
		{
			"ID": "20230115205208-knuj63u",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20230115205208-knuj63u",
				"updated": "20230115205212"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "哈希表：根据关键码值（Key value）直接进行访问的数据结构。通过把关键码值映射到表中一个位置来访问记录，以加快查找的速度。这个映射函数叫做哈希函数，存放记录的数组就叫做哈希表。"
				}
			]
		},
		{
			"ID": "20230115205212-aqrmbbx",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20230115205212-aqrmbbx",
				"updated": "20230115205216"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "树：由 n（n≥1）个有限结点组成的一个具有层次关系的集合，就像是一棵倒挂的树。"
				}
			]
		},
		{
			"ID": "20230115205217-wfl1vx4",
			"Type": "NodeHeading",
			"HeadingLevel": 2,
			"Properties": {
				"id": "20230115205217-wfl1vx4",
				"updated": "20230115205223"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "一、HashMap 的实现结构"
				}
			]
		},
		{
			"ID": "20230115205229-2s2m6ls",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20230115205229-2s2m6ls",
				"updated": "20230115205238"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "哈希表将键的 Hash 值映射到内存地址，即根据键获取对应的值，并将其存储到内存地址。也就是说 HashMap 是根据键的 Hash 值来决定对应值的存储位置。通过这种索引方式，HashMap 获取数据的速度会非常快。"
				}
			]
		},
		{
			"ID": "20230115205240-b1zlwi4",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20230115205240-b1zlwi4",
				"updated": "20230115205250"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "例如，存储键值对（x，“aa”）时，哈希表会通过哈希函数 f(x) 得到\"aa\"的实现存储位置。"
				}
			]
		},
		{
			"ID": "20230115205250-al3ft79",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20230115205250-al3ft79",
				"updated": "20230115205305"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "但也会有新的问题。如果再来一个 (y，“bb”)，哈希函数 f(y) 的哈希值跟之前 f(x) 是一样的，这样两个对象的存储地址就冲突了，这种现象就被称为哈希冲突。那么哈希表是怎么解决的呢？方式有很多，比如，"
				},
				{
					"Type": "NodeMark",
					"Data": "mark",
					"Children": [
						{
							"Type": "NodeMark2OpenMarker"
						},
						{
							"Type": "NodeText",
							"Data": "开放定址法、再哈希函数法和链地址法"
						},
						{
							"Type": "NodeMark2CloseMarker"
						}
					]
				},
				{
					"Type": "NodeText",
					"Data": "。"
				}
			]
		},
		{
			"ID": "20230115205224-ah909jh",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20230115205224-ah909jh",
				"updated": "20230115205320"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "开放定址法很简单，当发生哈希冲突时，如果哈希表未被装满，说明在哈希表中必然还有空位置，那么可以把 key 存放到冲突位置后面的空位置上去。这种方法存在着很多缺点，例如，查找、扩容等，所以我不建议你作为解决哈希冲突的首选。"
				}
			]
		},
		{
			"ID": "20230115205321-ijj385w",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20230115205321-ijj385w",
				"updated": "20230115205338"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "再哈希法顾名思义就是在同义词产生地址冲突时再计算另一个哈希函数地址，直到冲突不再发生，这种方法不易产生“聚集”，但却增加了计算时间。如果我们不考虑添加元素的时间成本，且对查询元素的要求极高，就可以考虑使用这种算法设计。"
				}
			]
		},
		{
			"ID": "20230115205339-2z33ezo",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20230115205339-2z33ezo",
				"updated": "20230115205418"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "HashMap 则是综合考虑了所有因素，采用链地址法解决哈希冲突问题。这种方法是采用了数组（哈希表）+ 链表的数据结构，当发生哈希冲突时，就用一个链表结构存储相同 Hash 值的数据。"
				}
			]
		},
		{
			"ID": "20230115205419-i468m4h",
			"Type": "NodeHeading",
			"HeadingLevel": 2,
			"Properties": {
				"id": "20230115205419-i468m4h",
				"updated": "20230115205559"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "二、HashMap 的重要属性"
				}
			]
		},
		{
			"ID": "20230115205600-s2ayq8h",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20230115205600-s2ayq8h",
				"updated": "20230115205607"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "从 HashMap 的源码中，我们可以发现，HashMap 是由一个 Node 数组构成，每个 Node 包含了一个 key-value 键值对。"
				}
			]
		},
		{
			"ID": "20230115205608-8ihpv8n",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20230115205608-8ihpv8n",
				"updated": "20230115205635"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker",
					"CodeBlockInfo": "amF2YQ=="
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "  transient Node\u003cK,V\u003e[] table;\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20230115205636-5921gps",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20230115205636-5921gps",
				"updated": "20230115205642"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "Node 类作为 HashMap 中的一个内部类，除了 key、value 两个属性外，还定义了一个 next 指针。当有哈希冲突时，HashMap 会用之前数组当中相同哈希值对应存储的 Node 对象，通过指针指向新增的相同哈希值的 Node 对象的引用。"
				}
			]
		},
		{
			"ID": "20230115205643-j3b679j",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20230115205643-j3b679j",
				"updated": "20230115205651"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker",
					"CodeBlockInfo": "amF2YQ=="
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "static class Node\u003cK,V\u003e implements Map.Entry\u003cK,V\u003e {\n        final int hash;\n        final K key;\n        V value;\n        Node\u003cK,V\u003e next;\n\n        Node(int hash, K key, V value, Node\u003cK,V\u003e next) {\n            this.hash = hash;\n            this.key = key;\n            this.value = value;\n            this.next = next;\n        }\n}\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20230115205700-dohntki",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20230115205700-dohntki",
				"updated": "20230115205708"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "HashMap 还有两个重要的属性：加载因子（loadFactor）和边界值（threshold）。在初始化 HashMap 时，就会涉及到这两个关键初始化参数。"
				}
			]
		},
		{
			"ID": "20230115205709-t5p0wfq",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20230115205709-t5p0wfq",
				"updated": "20230115205723"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker",
					"CodeBlockInfo": "amF2YQ=="
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "int threshold;\nfinal float loadFactor;\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20230115205853-1c9up5s",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20230115205853-1c9up5s",
				"updated": "20230115205900"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "LoadFactor 属性是用来间接设置 Entry 数组（哈希表）的内存空间大小，在初始 HashMap 不设置参数的情况下，默认 LoadFactor 值为 0.75。为什么是 0.75 这个值呢？"
				}
			]
		},
		{
			"ID": "20230115205901-oqpclwd",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20230115205901-oqpclwd",
				"updated": "20230115205907"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "这是因为对于使用链表法的哈希表来说，查找一个元素的平均时间是 O(1+n)，这里的 n 指的是遍历链表的长度，因此加载因子越大，对空间的利用就越充分，这就意味着链表的长度越长，查找效率也就越低。如果设置的加载因子太小，那么哈希表的数据将过于稀疏，对空间造成严重浪费。"
				}
			]
		},
		{
			"ID": "20230115205909-o5bssjq",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20230115205909-o5bssjq",
				"updated": "20230115205927"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "Entry 数组的 Threshold 是通过初始容量和 LoadFactor 计算所得，在初始 HashMap 不设置参数的情况下，默认边界值为 12。如果我们在初始化时，设置的初始化容量较小，HashMap 中 Node 的数量超过边界值，HashMap 就会调用 resize() 方法重新分配 table 数组。这将会导致 HashMap 的数组复制，迁移到另一块内存中去，从而影响 HashMap 的效率。"
				}
			]
		},
		{
			"ID": "20230115205937-6vigs0q",
			"Type": "NodeHeading",
			"HeadingLevel": 2,
			"Properties": {
				"id": "20230115205937-6vigs0q",
				"updated": "20230115205955"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "三、HashMap 添加元素优化"
				}
			]
		},
		{
			"ID": "20230115205944-oh3lj2y",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20230115205944-oh3lj2y",
				"updated": "20230115205957"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "初始化完成后，HashMap 就可以使用 put() 方法添加键值对了。从下面源码可以看出，当程序将一个 key-value 对添加到 HashMap 中，程序首先会根据该 key 的 hashCode() 返回值，再通过 hash() 方法计算出 hash 值，再通过 putVal 方法中的 (n - 1) \u0026 hash 决定该 Node 的存储位置。"
				}
			]
		},
		{
			"ID": "20230115210004-wevlhir",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20230115210004-wevlhir",
				"updated": "20230115210037"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker",
					"CodeBlockInfo": "amF2YQ=="
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "    public V put(K key, V value) {\n        return putVal(hash(key), key, value, false, true);\n    }\n\n    static final int hash(Object key) {\n\tint h;\n\treturn (key == null) ? 0 : (h = key.hashCode()) ^ (h \u003e\u003e\u003e 16);\n    }\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20230115210043-3y5ptmb",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20230115210043-3y5ptmb",
				"updated": "20230115210051"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker",
					"CodeBlockInfo": "amF2YQ=="
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "  if ((tab = table) == null || (n = tab.length) == 0)\n            n = (tab = resize()).length;\n        //通过putVal方法中的(n - 1) \u0026 hash决定该Node的存储位置\n        if ((p = tab[i = (n - 1) \u0026 hash]) == null)\n            tab[i] = newNode(hash, key, value, null);\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20230115210052-t6yggfa",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20230115210052-t6yggfa",
				"updated": "20230115210059"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "如果你不太清楚 hash() 以及 (n-1)\u0026hash 的算法，就请你看下面的详述。"
				}
			]
		},
		{
			"ID": "20230115210100-p99q2b1",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20230115210100-p99q2b1",
				"updated": "20230115210103"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "我们先来了解下 hash() 方法中的算法。如果我们没有使用 hash() 方法计算 hashCode，而是直接使用对象的 hashCode 值，会出现什么问题呢？"
				}
			]
		},
		{
			"ID": "20230115210104-mo9963y",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20230115210104-mo9963y",
				"updated": "20230115210137"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "假设要添加两个对象 a 和 b，如果数组长度是 16，这时对象 a 和 b 通过公式 (n - 1) \u0026 hash 运算，也就是 (16-1)＆a.hashCode 和 (16-1)＆b.hashCode，15 的二进制为 0000000000000000000000000001111，假设对象 A 的 hashCode 为 1000010001110001000001111000000，对象 B 的 hashCode 为 0111011100111000101000010100000，你会发现上述与运算结果都是 0。这样的哈希结果就太让人失望了，很明显不是一个好的哈希算法。"
				}
			]
		},
		{
			"ID": "20230115210148-65oym2z",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20230115210148-65oym2z",
				"updated": "20230115210148"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "但如果我们将 hashCode 值右移 16 位（h \u003e\u003e\u003e 16 代表无符号右移 16 位），也就是取 int 类型的一半，刚好可以将该二进制数对半切开，并且使用位异或运算（如果两个数对应的位置相反，则结果为 1，反之为 0），这样的话，就能避免上面的情况发生。这就是 hash() 方法的具体实现方式。简而言之，就是尽量打乱 hashCode 真正参与运算的低 16 位。"
				}
			]
		},
		{
			"ID": "20230115210149-ucnqmum",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20230115210149-ucnqmum",
				"updated": "20230115210156"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "我再来解释下 (n - 1) \u0026 hash 是怎么设计的，这里的 n 代表哈希表的长度，哈希表习惯将长度设置为 2 的 n 次方，这样恰好可以保证 (n - 1) \u0026 hash 的计算得到的索引值总是位于 table 数组的索引之内。例如：hash=15，n=16 时，结果为 15；hash=17，n=16 时，结果为 1。"
				}
			]
		},
		{
			"ID": "20230115210156-l7hjiam",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20230115210156-l7hjiam",
				"updated": "20230115210207"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "在获得 Node 的存储位置后，如果判断 Node 不在哈希表中，就新增一个 Node，并添加到哈希表中，整个流程我将用一张图来说明："
				}
			]
		},
		{
			"ID": "20230115210207-uiho3k1",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20230115210207-uiho3k1",
				"updated": "20230115210213"
			},
			"Children": [
				{
					"Type": "NodeImage",
					"Data": "span",
					"Children": [
						{
							"Type": "NodeBang"
						},
						{
							"Type": "NodeOpenBracket"
						},
						{
							"Type": "NodeLinkText",
							"Data": "image"
						},
						{
							"Type": "NodeCloseBracket"
						},
						{
							"Type": "NodeOpenParen"
						},
						{
							"Type": "NodeLinkDest",
							"Data": "assets/image-20230115210213-5ndat7s.png"
						},
						{
							"Type": "NodeCloseParen"
						}
					]
				},
				{
					"Type": "NodeText",
					"Data": "​"
				}
			]
		},
		{
			"ID": "20230115210214-9s343jk",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20230115210214-9s343jk",
				"updated": "20230115210339"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "从图中我们可以看出：在 JDK1.8 中，HashMap 引入了红黑树数据结构来提升链表的查询效率。"
				}
			]
		},
		{
			"ID": "20230115210340-lx9a8fg",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20230115210340-lx9a8fg",
				"updated": "20230115210344"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "这是因为链表的长度超过 8 后，红黑树的查询效率要比链表高，所以当链表超过 8 时，HashMap 就会将链表转换为红黑树，这里值得注意的一点是，这时的新增由于存在左旋、右旋效率会降低。讲到这里，我前面我提到的“因链表过长而导致的查询时间复杂度高”的问题，也就迎刃而解了。"
				}
			]
		},
		{
			"ID": "20230115210346-jycjdwh",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20230115210346-jycjdwh",
				"updated": "20230115210401"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "以下就是 put 的实现源码:"
				}
			]
		},
		{
			"ID": "20230115210402-jh31zuy",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20230115210402-jh31zuy",
				"updated": "20230115210412"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker",
					"CodeBlockInfo": "amF2YQ=="
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": " final V putVal(int hash, K key, V value, boolean onlyIfAbsent,\n                   boolean evict) {\n        Node\u003cK,V\u003e[] tab; Node\u003cK,V\u003e p; int n, i;\n        if ((tab = table) == null || (n = tab.length) == 0)\n//1、判断当table为null或者tab的长度为0时，即table尚未初始化，此时通过resize()方法得到初始化的table\n            n = (tab = resize()).length;\n        if ((p = tab[i = (n - 1) \u0026 hash]) == null)\n//1.1、此处通过（n - 1） \u0026 hash 计算出的值作为tab的下标i，并另p表示tab[i]，也就是该链表第一个节点的位置。并判断p是否为null\n            tab[i] = newNode(hash, key, value, null);\n//1.1.1、当p为null时，表明tab[i]上没有任何元素，那么接下来就new第一个Node节点，调用newNode方法返回新节点赋值给tab[i]\n        else {\n//2.1下面进入p不为null的情况，有三种情况：p为链表节点；p为红黑树节点；p是链表节点但长度为临界长度TREEIFY_THRESHOLD，再插入任何元素就要变成红黑树了。\n            Node\u003cK,V\u003e e; K k;\n            if (p.hash == hash \u0026\u0026\n                ((k = p.key) == key || (key != null \u0026\u0026 key.equals(k))))\n//2.1.1HashMap中判断key相同的条件是key的hash相同，并且符合equals方法。这里判断了p.key是否和插入的key相等，如果相等，则将p的引用赋给e\n\n                e = p;\n            else if (p instanceof TreeNode)\n//2.1.2现在开始了第一种情况，p是红黑树节点，那么肯定插入后仍然是红黑树节点，所以我们直接强制转型p后调用TreeNode.putTreeVal方法，返回的引用赋给e\n                e = ((TreeNode\u003cK,V\u003e)p).putTreeVal(this, tab, hash, key, value);\n            else {\n//2.1.3接下里就是p为链表节点的情形，也就是上述说的另外两类情况：插入后还是链表/插入后转红黑树。另外，上行转型代码也说明了TreeNode是Node的一个子类\n                for (int binCount = 0; ; ++binCount) {\n//我们需要一个计数器来计算当前链表的元素个数，并遍历链表，binCount就是这个计数器\n\n                    if ((e = p.next) == null) {\n                        p.next = newNode(hash, key, value, null);\n                        if (binCount \u003e= TREEIFY_THRESHOLD - 1) \n// 插入成功后，要判断是否需要转换为红黑树，因为插入后链表长度加1，而binCount并不包含新节点，所以判断时要将临界阈值减1\n                            treeifyBin(tab, hash);\n//当新长度满足转换条件时，调用treeifyBin方法，将该链表转换为红黑树\n                        break;\n                    }\n                    if (e.hash == hash \u0026\u0026\n                        ((k = e.key) == key || (key != null \u0026\u0026 key.equals(k))))\n                        break;\n                    p = e;\n                }\n            }\n            if (e != null) { // existing mapping for key\n                V oldValue = e.value;\n                if (!onlyIfAbsent || oldValue == null)\n                    e.value = value;\n                afterNodeAccess(e);\n                return oldValue;\n            }\n        }\n        ++modCount;\n        if (++size \u003e threshold)\n            resize();\n        afterNodeInsertion(evict);\n        return null;\n    }\n\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20230115210512-gwl5xw9",
			"Type": "NodeHeading",
			"HeadingLevel": 2,
			"Properties": {
				"id": "20230115210512-gwl5xw9",
				"updated": "20230115210522"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "四、HashMap 获取元素优化"
				}
			]
		},
		{
			"ID": "20230115210522-jpei4e5",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20230115210522-jpei4e5",
				"updated": "20230115210526"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "当 HashMap 中只存在数组，而数组中没有 Node 链表时，是 HashMap 查询数据性能最好的时候。一旦发生大量的哈希冲突，就会产生 Node 链表，这个时候每次查询元素都可能遍历 Node 链表，从而降低查询数据的性能。"
				}
			]
		},
		{
			"ID": "20230115210527-4tk5bjc",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20230115210527-4tk5bjc",
				"updated": "20230115210704"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "特别是在链表长度过长的情况下，性能将明显降低，红黑树的使用很好地解决了这个问题，使得查询的平均复杂度降低到了 O(log(n))，链表越长，使用黑红树替换后的查询效率提升就越明显。"
				}
			]
		},
		{
			"ID": "20230115210705-ftsufnn",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20230115210705-ftsufnn",
				"updated": "20230115210709"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "我们在编码中也可以优化 HashMap 的性能，例如，重写 key 值的 hashCode() 方法，降低哈希冲突，从而减少链表的产生，高效利用哈希表，达到提高性能的效果。"
				}
			]
		},
		{
			"ID": "20230115210710-0y7munp",
			"Type": "NodeHeading",
			"HeadingLevel": 2,
			"Properties": {
				"id": "20230115210710-0y7munp",
				"updated": "20230115210736"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "五、HashMap 扩容优化"
				}
			]
		},
		{
			"ID": "20230115210736-cdhirtn",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20230115210736-cdhirtn",
				"updated": "20230115210744"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "HashMap 也是数组类型的数据结构，所以一样存在扩容的情况。"
				}
			]
		},
		{
			"ID": "20230115210745-ghcffpe",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20230115210745-ghcffpe",
				"updated": "20230115210813"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "在 JDK1.7 中，HashMap 整个扩容过程就是分别取出数组元素，一般该元素是最后一个放入链表中的元素，然后遍历以该元素为头的单向链表元素，依据每个被遍历元素的 hash 值计算其在新数组中的下标，然后进行交换。这样的扩容方式会将原来哈希冲突的单向链表尾部变成扩容后单向链表的头部。"
				}
			]
		},
		{
			"ID": "20230115210814-2dk7f53",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20230115210814-2dk7f53",
				"updated": "20230115210818"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "而在 JDK 1.8 中，HashMap 对扩容操作做了优化。由于扩容数组的长度是 2 倍关系，所以对于假设初始 tableSize = 4 要扩容到 8 来说就是 0100 到 1000 的变化（左移一位就是 2 倍），在扩容中只用判断原来的 hash 值和左移动的一位（newtable 的值）按位与操作是 0 或 1 就行，0 的话索引不变，1 的话索引变成原索引加上扩容前数组。"
				}
			]
		},
		{
			"ID": "20230115210818-931d1uj",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20230115210818-931d1uj",
				"updated": "20230115210823"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "之所以能通过这种“与运算“来重新分配索引，是因为 hash 值本来就是随机的，而 hash 按位与上 newTable 得到的 0（扩容前的索引位置）和 1（扩容前索引位置加上扩容前数组长度的数值索引处）就是随机的，所以扩容的过程就能把之前哈希冲突的元素再随机分布到不同的索引中去。"
				}
			]
		},
		{
			"ID": "20230115210823-qnm3g26",
			"Type": "NodeHeading",
			"HeadingLevel": 2,
			"Properties": {
				"id": "20230115210823-qnm3g26",
				"updated": "20230115210829"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "六、总结"
				}
			]
		},
		{
			"ID": "20230115210830-zj5mpca",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20230115210830-zj5mpca",
				"updated": "20230115210834"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "HashMap 通过哈希表数据结构的形式来存储键值对，这种设计的好处就是查询键值对的效率高。"
				}
			]
		},
		{
			"ID": "20230115210835-m4b6qap",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20230115210835-m4b6qap",
				"updated": "20230115210839"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "我们在使用 HashMap 时，可以结合自己的场景来设置初始容量和加载因子两个参数。当查询操作较为频繁时，我们可以适当地减少加载因子；如果对内存利用率要求比较高，我可以适当的增加加载因子。"
				}
			]
		},
		{
			"ID": "20230115210839-l2nsshd",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20230115210839-l2nsshd",
				"updated": "20230115210854"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "我们还可以在预知存储数据量的情况下，提前设置初始容量（初始容量 = 预知数据量 / 加载因子）。这样做的好处是可以减少 resize() 操作，提高 HashMap 的效率。"
				}
			]
		},
		{
			"ID": "20230115210855-3as7jo9",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20230115210855-3as7jo9",
				"updated": "20230115210905"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "HashMap 还使用了数组 + 链表这两种数据结构相结合的方式实现了链地址法，当有哈希值冲突时，就可以将冲突的键值对链成一个链表。"
				}
			]
		},
		{
			"ID": "20230115210907-3iax64r",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20230115210907-3iax64r",
				"updated": "20230115210920"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "但这种方式又存在一个性能问题，如果链表过长，查询数据的时间复杂度就会增加。HashMap 就在 Java8 中使用了红黑树来解决链表过长导致的查询性能下降问题。以下是 HashMap 的数据结构图："
				}
			]
		},
		{
			"ID": "20230115210920-xrs41gx",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20230115210920-xrs41gx",
				"updated": "20230115210924"
			},
			"Children": [
				{
					"Type": "NodeImage",
					"Data": "span",
					"Children": [
						{
							"Type": "NodeBang"
						},
						{
							"Type": "NodeOpenBracket"
						},
						{
							"Type": "NodeLinkText",
							"Data": "image"
						},
						{
							"Type": "NodeCloseBracket"
						},
						{
							"Type": "NodeOpenParen"
						},
						{
							"Type": "NodeLinkDest",
							"Data": "assets/image-20230115210924-1w2lsfc.png"
						},
						{
							"Type": "NodeCloseParen"
						}
					]
				},
				{
					"Type": "NodeText",
					"Data": "​"
				}
			]
		},
		{
			"ID": "20230115210924-ef2s7h6",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20230115210924-ef2s7h6"
			}
		}
	]
}